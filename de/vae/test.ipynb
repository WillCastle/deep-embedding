{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[34., 53., 68., 44., 26.,  1., 15., 19.,  9., 35., 76., 26., 12., 53.,\n",
       "         26.,  1.,  7., 15.,  7., 15.,  7., 26.,  1., 35., 26.,  1.,  1.,  1.,\n",
       "          1., 26.,  1.,  1., 20., 40.,  1., 19., 16., 44., 32.,  9., 35., 47.],\n",
       "        [26.,  1., 16., 20., 19., 64., 26.,  1., 15.,  1., 56., 22., 15., 19.,\n",
       "         26., 55., 70., 26., 16., 15.,  9., 26.,  1., 26., 36., 17.,  9.,  1.,\n",
       "         20.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [47., 40., 15.,  8., 76., 40., 15.,  8., 30., 16.,  1., 35., 19., 40.,\n",
       "         15.,  8., 32., 20.,  1., 10., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from prepare.text.tokenizer import train_tokenizer\n",
    "\n",
    "text_batch = [\n",
    "    \"There are some unseen words here banana zen 游때 but also some seen text\",\n",
    "    \"Lots of unknowns in this one I expect\",\n",
    "    \"text and words and tokens and stuff\"\n",
    "]\n",
    "\n",
    "test_tokenizer_path = \"C:/Users/willf/DataScience/Repos/deep-embedding/de/vae/prepare/text/test_data/test_bpe_tokenizer.json\"\n",
    "base_data_path = Path(\"C:/Users/willf/DataScience/Repos/deep-embedding/de/vae/prepare/text/test_data\")\n",
    "data_paths = [str(path) for path in base_data_path.glob(\"**/*.txt\")]\n",
    "\n",
    "tk = train_tokenizer(data_paths=data_paths, save_path=test_tokenizer_path)\n",
    "\n",
    "\n",
    "encoded_batch = tk.encode_batch(text_batch)\n",
    "encoded_batch = torch.Tensor([sequence.ids for sequence in encoded_batch])\n",
    "encoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder_module): StackedEncoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=42, out_features=16, bias=True)\n",
      "        (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=4, bias=True)\n",
      "        (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=2, bias=True)\n",
      "        (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_module): StackedEncoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "        (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "        (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Linear(in_features=16, out_features=42, bias=True)\n",
      "        (1): BatchNorm1d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (latent_mean): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (latent_log_variance): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from custom_model import VAE\n",
    "vae = VAE(input_dim=42, hidden_dims=[16, 4], latent_dim=2)\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Name: this_var\n",
      "Shape(1, 1, 1)\n",
      "Type: <class 'list'>\n",
      "Variable: [[array([0])]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def print_shape_type(var_name: str, var):\n",
    "    print(f\"Variable Name: {var_name}\\nShape{np.shape(var)}\\nType: {type(var)}\\nVariable: {var}\\n\")\n",
    "\n",
    "this_var = [[(np.array([int(0)]))]]\n",
    "print_shape_type(\"this_var\", this_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Name: text_batch\n",
      "Shape(3,)\n",
      "Type: <class 'list'>\n",
      "Variable: ['There are some unseen words here banana zen 游때 but also some seen text', 'text and words and tokens and stuff', 'Lots of unknowns in this one I expect']\n",
      "\n",
      "Variable Name: sorted_batch\n",
      "Shape(3,)\n",
      "Type: <class 'list'>\n",
      "Variable: ['There are some unseen words here banana zen 游때 but also some seen text', 'Lots of unknowns in this one I expect', 'text and words and tokens and stuff']\n",
      "\n",
      "Variable Name: tokenized_batch\n",
      "Shapetorch.Size([3, 42])\n",
      "Type: <class 'torch.Tensor'>\n",
      "Variable: tensor([[34, 53, 68, 44, 26,  1, 15, 19,  9, 35, 76, 26, 12, 53, 26,  1,  7, 15,\n",
      "          7, 15,  7, 26,  1, 35, 26,  1,  1,  1,  1, 26,  1,  1, 20, 40,  1, 19,\n",
      "         16, 44, 32,  9, 35, 47],\n",
      "        [26,  1, 16, 20, 19, 64, 26,  1, 15,  1, 56, 22, 15, 19, 26, 55, 70, 26,\n",
      "         16, 15,  9, 26,  1, 26, 36, 17,  9,  1, 20,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0],\n",
      "        [47, 40, 15,  8, 76, 40, 15,  8, 30, 16,  1, 35, 19, 40, 15,  8, 32, 20,\n",
      "          1, 10, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0]], dtype=torch.int32)\n",
      "\n",
      "Variable Name: transposed_batch\n",
      "Shapetorch.Size([42, 3])\n",
      "Type: <class 'torch.Tensor'>\n",
      "Variable: tensor([[34, 26, 47],\n",
      "        [53,  1, 40],\n",
      "        [68, 16, 15],\n",
      "        [44, 20,  8],\n",
      "        [26, 19, 76],\n",
      "        [ 1, 64, 40],\n",
      "        [15, 26, 15],\n",
      "        [19,  1,  8],\n",
      "        [ 9, 15, 30],\n",
      "        [35,  1, 16],\n",
      "        [76, 56,  1],\n",
      "        [26, 22, 35],\n",
      "        [12, 15, 19],\n",
      "        [53, 19, 40],\n",
      "        [26, 26, 15],\n",
      "        [ 1, 55,  8],\n",
      "        [ 7, 70, 32],\n",
      "        [15, 26, 20],\n",
      "        [ 7, 16,  1],\n",
      "        [15, 15, 10],\n",
      "        [ 7,  9, 10],\n",
      "        [26, 26,  0],\n",
      "        [ 1,  1,  0],\n",
      "        [35, 26,  0],\n",
      "        [26, 36,  0],\n",
      "        [ 1, 17,  0],\n",
      "        [ 1,  9,  0],\n",
      "        [ 1,  1,  0],\n",
      "        [ 1, 20,  0],\n",
      "        [26,  0,  0],\n",
      "        [ 1,  0,  0],\n",
      "        [ 1,  0,  0],\n",
      "        [20,  0,  0],\n",
      "        [40,  0,  0],\n",
      "        [ 1,  0,  0],\n",
      "        [19,  0,  0],\n",
      "        [16,  0,  0],\n",
      "        [44,  0,  0],\n",
      "        [32,  0,  0],\n",
      "        [ 9,  0,  0],\n",
      "        [35,  0,  0],\n",
      "        [47,  0,  0]], dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_batch = [\n",
    "    \"There are some unseen words here banana zen 游때 but also some seen text\",\n",
    "    \"text and words and tokens and stuff\",\n",
    "    \"Lots of unknowns in this one I expect\",\n",
    "]\n",
    "print_shape_type(\"text_batch\", text_batch)\n",
    "sorted_batch = sorted(text_batch, key=len, reverse=True)\n",
    "print_shape_type(\"sorted_batch\", sorted_batch)\n",
    "tokenized_batch = tk.encode_batch(sorted_batch)\n",
    "tokenized_batch = torch.Tensor([sequence.ids for sequence in tokenized_batch]).int()\n",
    "print_shape_type(\"tokenized_batch\", tokenized_batch)\n",
    "transposed_batch = tokenized_batch.T\n",
    "print_shape_type(\"transposed_batch\", transposed_batch)\n",
    "\n",
    "# print_shape_type(\"\", )\n",
    "# print_shape_type(\"\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[34, 26, 47],\n",
       "        [53,  1, 40],\n",
       "        [68, 16, 15],\n",
       "        [44, 20,  8],\n",
       "        [26, 19, 76],\n",
       "        [ 1, 64, 40],\n",
       "        [15, 26, 15],\n",
       "        [19,  1,  8],\n",
       "        [ 9, 15, 30],\n",
       "        [35,  1, 16],\n",
       "        [76, 56,  1],\n",
       "        [26, 22, 35],\n",
       "        [12, 15, 19],\n",
       "        [53, 19, 40],\n",
       "        [26, 26, 15],\n",
       "        [ 1, 55,  8],\n",
       "        [ 7, 70, 32],\n",
       "        [15, 26, 20],\n",
       "        [ 7, 16,  1],\n",
       "        [15, 15, 10],\n",
       "        [ 7,  9, 10],\n",
       "        [26, 26,  0],\n",
       "        [ 1,  1,  0],\n",
       "        [35, 26,  0],\n",
       "        [26, 36,  0],\n",
       "        [ 1, 17,  0],\n",
       "        [ 1,  9,  0],\n",
       "        [ 1,  1,  0],\n",
       "        [ 1, 20,  0],\n",
       "        [26,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [20,  0,  0],\n",
       "        [40,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [19,  0,  0],\n",
       "        [16,  0,  0],\n",
       "        [44,  0,  0],\n",
       "        [32,  0,  0],\n",
       "        [ 9,  0,  0],\n",
       "        [35,  0,  0],\n",
       "        [47,  0,  0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tokenizers\n",
    "class TextPreprocessor():\n",
    "    \"\"\"\n",
    "    TODO.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            tokenizer: tokenizers.Tokenizer,\n",
    "            ):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, text_batch: list[str]):\n",
    "        sorted_batch = sorted(text_batch, key=len, reverse=True)\n",
    "        tokenized_batch = self.tokenizer.encode_batch(sorted_batch)\n",
    "        tokenized_batch = torch.Tensor([sequence.ids for sequence in tokenized_batch]).int()\n",
    "        return tokenized_batch.T\n",
    "\n",
    "text_batch = [\n",
    "    \"There are some unseen words here banana zen 游때 but also some seen text\",\n",
    "    \"text and words and tokens and stuff\",\n",
    "    \"Lots of unknowns in this one I expect\",\n",
    "]\n",
    "text_preprocessor = TextPreprocessor(tokenizer=tk)\n",
    "\n",
    "processed_text_batch = text_preprocessor(text_batch)\n",
    "processed_text_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[34,\n",
       "  53,\n",
       "  68,\n",
       "  44,\n",
       "  26,\n",
       "  1,\n",
       "  15,\n",
       "  19,\n",
       "  9,\n",
       "  35,\n",
       "  76,\n",
       "  26,\n",
       "  12,\n",
       "  53,\n",
       "  26,\n",
       "  1,\n",
       "  7,\n",
       "  15,\n",
       "  7,\n",
       "  15,\n",
       "  7,\n",
       "  26,\n",
       "  1,\n",
       "  35,\n",
       "  26,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  26,\n",
       "  1,\n",
       "  1,\n",
       "  20,\n",
       "  40,\n",
       "  1,\n",
       "  19,\n",
       "  16,\n",
       "  44,\n",
       "  32,\n",
       "  9,\n",
       "  35,\n",
       "  47],\n",
       " [26,\n",
       "  1,\n",
       "  16,\n",
       "  20,\n",
       "  19,\n",
       "  64,\n",
       "  26,\n",
       "  1,\n",
       "  15,\n",
       "  1,\n",
       "  56,\n",
       "  22,\n",
       "  15,\n",
       "  19,\n",
       "  26,\n",
       "  55,\n",
       "  70,\n",
       "  26,\n",
       "  16,\n",
       "  15,\n",
       "  9,\n",
       "  26,\n",
       "  1,\n",
       "  26,\n",
       "  36,\n",
       "  17,\n",
       "  9,\n",
       "  1,\n",
       "  20,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [47,\n",
       "  40,\n",
       "  15,\n",
       "  8,\n",
       "  76,\n",
       "  40,\n",
       "  15,\n",
       "  8,\n",
       "  30,\n",
       "  16,\n",
       "  1,\n",
       "  35,\n",
       "  19,\n",
       "  40,\n",
       "  15,\n",
       "  8,\n",
       "  32,\n",
       "  20,\n",
       "  1,\n",
       "  10,\n",
       "  10,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text_batch.T.int().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' There are some nseen words here anana en  t aso some seen text',\n",
       " ' ots of nnowns in this one  expet',\n",
       " ' text and words and toens and stff']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.decode_batch(processed_text_batch.T.int().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 42])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = round(tk.get_vocab_size() ** 0.25)\n",
    "test_net = torch.nn.Sequential(torch.nn.Embedding(3, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NVMLError_LibraryNotFound",
     "evalue": "NVML Shared Library Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\willf\\miniconda3\\envs\\de\\lib\\site-packages\\pynvml.py:641\u001b[0m, in \u001b[0;36m_LoadNvmlLibrary\u001b[1;34m()\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[39mif\u001b[39;00m (sys\u001b[39m.\u001b[39mplatform[:\u001b[39m3\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[39m# cdecl calling convention\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     \u001b[39m# load nvml.dll from %ProgramFiles%/NVIDIA Corporation/NVSMI/nvml.dll\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m     nvmlLib \u001b[39m=\u001b[39m CDLL(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(os\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mProgramFiles\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mC:/Program Files\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mNVIDIA Corporation/NVSMI/nvml.dll\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    642\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    643\u001b[0m     \u001b[39m# assume linux\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willf\\miniconda3\\envs\\de\\lib\\ctypes\\__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 374\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[0;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'C:\\Program Files\\NVIDIA Corporation\\NVSMI\\nvml.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNVMLError_LibraryNotFound\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     info \u001b[39m=\u001b[39m nvmlDeviceGetMemoryInfo(handle)\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGPU memory occupied: \u001b[39m\u001b[39m{\u001b[39;00minfo\u001b[39m.\u001b[39mused\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m1024\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m MB.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m print_gpu_utilization()\n",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m, in \u001b[0;36mprint_gpu_utilization\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_gpu_utilization\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     nvmlInit()\n\u001b[0;32m      4\u001b[0m     handle \u001b[39m=\u001b[39m nvmlDeviceGetHandleByIndex(\u001b[39m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m     info \u001b[39m=\u001b[39m nvmlDeviceGetMemoryInfo(handle)\n",
      "File \u001b[1;32mc:\\Users\\willf\\miniconda3\\envs\\de\\lib\\site-packages\\pynvml.py:608\u001b[0m, in \u001b[0;36mnvmlInit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnvmlInit\u001b[39m():\n\u001b[1;32m--> 608\u001b[0m     _LoadNvmlLibrary()\n\u001b[0;32m    610\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    611\u001b[0m     \u001b[39m# Initialize the library\u001b[39;00m\n\u001b[0;32m    612\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    613\u001b[0m     fn \u001b[39m=\u001b[39m _nvmlGetFunctionPointer(\u001b[39m\"\u001b[39m\u001b[39mnvmlInit_v2\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\willf\\miniconda3\\envs\\de\\lib\\site-packages\\pynvml.py:646\u001b[0m, in \u001b[0;36m_LoadNvmlLibrary\u001b[1;34m()\u001b[0m\n\u001b[0;32m    644\u001b[0m         nvmlLib \u001b[39m=\u001b[39m CDLL(\u001b[39m\"\u001b[39m\u001b[39mlibnvidia-ml.so.1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    645\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m ose:\n\u001b[1;32m--> 646\u001b[0m     _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m (nvmlLib \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    648\u001b[0m     _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)\n",
      "File \u001b[1;32mc:\\Users\\willf\\miniconda3\\envs\\de\\lib\\site-packages\\pynvml.py:310\u001b[0m, in \u001b[0;36m_nvmlCheckReturn\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_nvmlCheckReturn\u001b[39m(ret):\n\u001b[0;32m    309\u001b[0m     \u001b[39mif\u001b[39;00m (ret \u001b[39m!=\u001b[39m NVML_SUCCESS):\n\u001b[1;32m--> 310\u001b[0m         \u001b[39mraise\u001b[39;00m NVMLError(ret)\n\u001b[0;32m    311\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mNVMLError_LibraryNotFound\u001b[0m: NVML Shared Library Not Found"
     ]
    }
   ],
   "source": [
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b20c1bcf20f03c32649c64023c2da95982acdbebe984ed7023ddf72d9fd3d1c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
